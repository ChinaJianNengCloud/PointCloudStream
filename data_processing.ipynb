{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/dara_pose_r_cam_u_lincheng'), PosixPath('data/data_pose_r_cam_u_lincheng2'), PosixPath('data/data_pose_r_cam_u_3'), PosixPath('data/data_pose_r_cam_u_1'), PosixPath('data/data_ss_2'), PosixPath('data/data_pose_r_cam_u_lincheng'), PosixPath('data/data_ss_'), PosixPath('data/data_pose_r_cam_u_lin'), PosixPath('data/data_pose_r_cam_u_2'), PosixPath('data/dara_pose_r_cam_u_lin'), PosixPath('data/resources'), PosixPath('data/data_pose_r_cam_u_4'), PosixPath('data/data_pose_r_cam_u_lincheng3')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"./data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "file_contents = {}\n",
    "for json_f in path.rglob(\"sa*.json\"):\n",
    "    json_contents = json.loads(json_f.read_text())\n",
    "    print(len(json_contents))\n",
    "    file_contents.update(json_contents)\n",
    "    # break\n",
    "\n",
    "# Sort the file_contents by the 'prompt' field\n",
    "sorted_contents = OrderedDict(\n",
    "    sorted(file_contents.items(), key=lambda item: int(item[1]['prompt']))\n",
    ")\n",
    "\n",
    "output = Path(\"./data\") / \"lincheng\"\n",
    "output.mkdir(exist_ok=True)\n",
    "with open(output / \"saved_data.json\", \"w\") as f:\n",
    "    json.dump(sorted_contents, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolo finetun using different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics.utils.checks import check_requirements\n",
    "from ultralytics.utils.downloads import download\n",
    "from ultralytics.utils.ops import xyxy2xywhn\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "check_requirements(('pycocotools>=2.0',))\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Make Directories\n",
    "dir = Path('/home/capre/disk_4/yutao/ultralytics/datasets/Objects365')  # dataset root dir\n",
    "for p in 'images', 'labels':\n",
    "    (dir / p).mkdir(parents=True, exist_ok=True)\n",
    "    for q in 'train', 'val':\n",
    "        (dir / p / q).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Train, Val Splits\n",
    "for split, patches in [('train', 50 + 1), ('val', 43 + 1)]:\n",
    "    print(f\"Processing {split} in {patches} patches ...\")\n",
    "    images, labels = dir / 'images' / split, dir / 'labels' / split\n",
    "\n",
    "    # Download\n",
    "    url = f\"https://dorc.ks3-cn-beijing.ksyun.com/data-set/2020Objects365%E6%95%B0%E6%8D%AE%E9%9B%86/{split}/\"\n",
    "    if split == 'train':\n",
    "        download([f'{url}zhiyuan_objv2_{split}.tar.gz'], dir=dir)  # annotations json\n",
    "        download([f'{url}patch{i}.tar.gz' for i in range(patches)], dir=images, curl=True, threads=8)\n",
    "    elif split == 'val':\n",
    "        download([f'{url}zhiyuan_objv2_{split}.json'], dir=dir)  # annotations json\n",
    "        download([f'{url}images/v1/patch{i}.tar.gz' for i in range(15 + 1)], dir=images, curl=True, threads=8)\n",
    "        download([f'{url}images/v2/patch{i}.tar.gz' for i in range(16, patches)], dir=images, curl=True, threads=8)\n",
    "\n",
    "    # Move\n",
    "    for f in tqdm(images.rglob('*.jpg'), desc=f'Moving {split} images'):\n",
    "        f.rename(images / f.name)  # move to /images/{split}\n",
    "\n",
    "    # Labels\n",
    "    coco = COCO(dir / f'zhiyuan_objv2_{split}.json')\n",
    "    names = [x[\"name\"] for x in coco.loadCats(coco.getCatIds())]\n",
    "    for cid, cat in enumerate(names):\n",
    "        catIds = coco.getCatIds(catNms=[cat])\n",
    "        imgIds = coco.getImgIds(catIds=catIds)\n",
    "        for im in tqdm(coco.loadImgs(imgIds), desc=f'Class {cid + 1}/{len(names)} {cat}'):\n",
    "            width, height = im[\"width\"], im[\"height\"]\n",
    "            path = Path(im[\"file_name\"])  # image filename\n",
    "            try:\n",
    "                with open(labels / path.with_suffix('.txt').name, 'a') as file:\n",
    "                    annIds = coco.getAnnIds(imgIds=im[\"id\"], catIds=catIds, iscrowd=None)\n",
    "                    for a in coco.loadAnns(annIds):\n",
    "                        x, y, w, h = a['bbox']  # bounding box in xywh (xy top-left corner)\n",
    "                        xyxy = np.array([x, y, x + w, y + h])[None]  # pixels(1,4)\n",
    "                        x, y, w, h = xyxy2xywhn(xyxy, w=width, h=height, clip=True)[0]  # normalized and clipped\n",
    "                        file.write(f\"{cid} {x:.5f} {y:.5f} {w:.5f} {h:.5f}\\n\")\n",
    "            except Exception as e:\n",
    "                print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "# os.chdir(\"/home/capre/disk_4/yutao/ultralytics\")\n",
    "# Load a model\n",
    "model = YOLO(\"/home/capre/Point-Cloud-Stream/runs/segment/train6/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "# results = model.train(data=\"Objects365.yaml\", epochs=100, imgsz=640)\n",
    "image_path = '/home/capre/disk_4/yutao/data/resources/0a7ee4d0cf344e15a81c68be0be1fb96_color_2.png'\n",
    "res= model.predict(source=image_path, save=False, verbose=False)\n",
    "res[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolo finetune for breast seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11x-seg.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"/home/capre/disk_4/yutao/breast-seg/dataset3/dataset.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# masks filename align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def add_leading_zeros_to_masks(masks_dir, total_digits=4):\n",
    "    \"\"\"\n",
    "    将 masks_dir 中的文件名加上前导零，使其成为指定长度的数字字符串。\n",
    "\n",
    "    参数：\n",
    "    - masks_dir: 掩码文件夹的路径\n",
    "    - total_digits: 文件名应达到的总位数，默认为4\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(masks_dir):\n",
    "        # 分离文件名和扩展名\n",
    "        basename, extension = os.path.splitext(filename)\n",
    "        try:\n",
    "            # 将文件名转换为整数，以确保文件名是数字\n",
    "            number = int(basename)\n",
    "            # 格式化新的文件名，添加前导零\n",
    "            new_basename = f\"{number:0{total_digits}d}\"\n",
    "            new_filename = new_basename + extension\n",
    "            # 构建完整的源和目标路径\n",
    "            src = os.path.join(masks_dir, filename)\n",
    "            dst = os.path.join(masks_dir, new_filename)\n",
    "            # 重命名文件\n",
    "            os.rename(src, dst)\n",
    "            print(f\"重命名：{filename} -> {new_filename}\")\n",
    "        except ValueError:\n",
    "            print(f\"跳过非数字文件名：{filename}\")\n",
    "\n",
    "# 使用示例：\n",
    "masks_dir = '/home/capre/disk_4/yutao/breast-seg/masks'  # 替换为您的 masks 文件夹路径\n",
    "add_leading_zeros_to_masks(masks_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolo dataset make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "images_dir = '/home/capre/disk_4/yutao/breast-seg/images'  # Replace with your images directory\n",
    "masks_dir = '/home/capre/disk_4/yutao/breast-seg/masks'      # Replace with your masks directory\n",
    "dataset_root = '/home/capre/disk_4/yutao/breast-seg/dataset2'  # Replace with your dataset root directory\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(os.path.join(dataset_root, 'images', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'images', 'val'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'labels', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'labels', 'val'), exist_ok=True)\n",
    "\n",
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Shuffle and split into train and val\n",
    "random.shuffle(image_files)\n",
    "split_index = int(len(image_files) * 0.8)\n",
    "train_files = image_files[:split_index]\n",
    "val_files = image_files[split_index:]\n",
    "\n",
    "def process_dataset(phase, files):\n",
    "    for image_file in files:\n",
    "        # Read image and mask\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        mask_path = os.path.join(masks_dir, image_file)  # Assuming mask has the same name\n",
    "        image = cv2.imread(image_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Check if mask exists\n",
    "        if mask is None:\n",
    "            print(f\"Mask not found for image {image_file}\")\n",
    "            continue\n",
    "\n",
    "        height, width = mask.shape\n",
    "        # Threshold mask to binary\n",
    "        _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create label file\n",
    "        label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "        label_path = os.path.join(dataset_root, 'labels', phase, label_file)\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            for contour in contours:\n",
    "                # Simplify contour\n",
    "                epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "                contour = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "                # Flatten contour array\n",
    "                contour = contour.squeeze()\n",
    "                if contour.ndim != 2:\n",
    "                    continue  # Skip if contour is not 2D\n",
    "\n",
    "                # Normalize coordinates\n",
    "                normalized_contour = contour.astype(np.float32)\n",
    "                normalized_contour[:, 0] /= width\n",
    "                normalized_contour[:, 1] /= height\n",
    "\n",
    "                # Flatten and convert to list\n",
    "                contour_list = normalized_contour.flatten().tolist()\n",
    "\n",
    "                # Write to file (class index is 0)\n",
    "                line = '0 ' + ' '.join(map(str, contour_list))\n",
    "                f.write(line + '\\n')\n",
    "\n",
    "        # Copy image to dataset folder\n",
    "        shutil.copy(image_path, os.path.join(dataset_root, 'images', phase, image_file))\n",
    "\n",
    "        # Visualization (optional)\n",
    "        # if random.random() < 0.05:  # Adjust the probability as needed\n",
    "        #     # Plot image and contours\n",
    "        #     plt.figure(figsize=(10, 10))\n",
    "        #     plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        #     for contour in contours:\n",
    "        #         contour = contour.squeeze()\n",
    "        #         plt.plot(contour[:, 0], contour[:, 1], linewidth=2)\n",
    "        #     plt.title(f\"{phase} - {image_file}\")\n",
    "        #     plt.axis('off')\n",
    "        #     plt.show()\n",
    "\n",
    "# Process train and val datasets\n",
    "process_dataset('train', train_files)\n",
    "process_dataset('val', val_files)\n",
    "\n",
    "# Generate dataset YAML file\n",
    "dataset_yaml = os.path.join(dataset_root, 'dataset.yaml')\n",
    "with open(dataset_yaml, 'w') as f:\n",
    "    f.write(f\"path: {dataset_root}\\n\")\n",
    "    f.write(\"train: images/train\\n\")\n",
    "    f.write(\"val: images/val\\n\")\n",
    "    f.write(\"test: \\n\\n\")\n",
    "    f.write(\"names:\\n\")\n",
    "    f.write(\"  0: object\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add label from predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define paths\n",
    "images_dir = '/home/capre/disk_4/yutao/breast-seg/images'  # Replace with your images directory\n",
    "masks_dir = '/home/capre/disk_4/yutao/breast-seg/masks'      # Replace with your masks directory\n",
    "dataset_root = '/home/capre/disk_4/yutao/breast-seg/dataset3'  # Replace with your dataset root directory\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(os.path.join(dataset_root, 'images', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'images', 'val'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'labels', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'labels', 'val'), exist_ok=True)\n",
    "\n",
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Shuffle and split into train and val\n",
    "random.shuffle(image_files)\n",
    "split_index = int(len(image_files) * 0.8)\n",
    "train_files = image_files[:split_index]\n",
    "val_files = image_files[split_index:]\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolo11x-seg.pt')  # Replace with the correct path to your model\n",
    "\n",
    "# Get class names and assign a new class ID for your mask label\n",
    "class_names = model.names  # A dictionary {class_id: class_name}\n",
    "max_class_id = max(class_names.keys())\n",
    "mask_class_id = max_class_id + 1\n",
    "class_names[mask_class_id] = 'breast'  # Replace 'breast' with your class name\n",
    "\n",
    "def process_dataset(phase, files):\n",
    "    for image_file in files:\n",
    "        # Read image and mask\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        mask_path = os.path.join(masks_dir, image_file)  # Assuming mask has the same name\n",
    "        image = cv2.imread(image_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Check if mask exists\n",
    "        if mask is None:\n",
    "            print(f\"Mask not found for image {image_file}\")\n",
    "            continue\n",
    "\n",
    "        original_height, original_width = image.shape[:2]\n",
    "\n",
    "        # Run the model to get predictions\n",
    "        results = model.predict(source=image, save=False, verbose=False)\n",
    "        result = results[0]\n",
    "\n",
    "        # Create label file\n",
    "        label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "        label_path = os.path.join(dataset_root, 'labels', phase, label_file)\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            # Process predicted masks\n",
    "            if hasattr(result, 'masks') and result.masks is not None:\n",
    "                pred_masks = result.masks.data.cpu().numpy()\n",
    "                pred_classes = result.boxes.cls.cpu().numpy().astype(int)\n",
    "                for mask_pred, class_id in zip(pred_masks, pred_classes):\n",
    "                    # Convert mask to binary image\n",
    "                    mask_pred = (mask_pred > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "                    # Resize mask back to original image size\n",
    "                    mask_pred_resized = cv2.resize(mask_pred, (original_width, original_height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "                    # Find contours\n",
    "                    contours, _ = cv2.findContours(mask_pred_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                    for contour in contours:\n",
    "                        # Simplify contour\n",
    "                        epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "                        contour = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "                        # Flatten contour array\n",
    "                        contour = contour.squeeze()\n",
    "                        if contour.ndim != 2:\n",
    "                            continue  # Skip if contour is not 2D\n",
    "\n",
    "                        # Normalize coordinates\n",
    "                        normalized_contour = contour.astype(np.float32)\n",
    "                        normalized_contour[:, 0] /= original_width\n",
    "                        normalized_contour[:, 1] /= original_height\n",
    "\n",
    "                        # Flatten and convert to list\n",
    "                        contour_list = normalized_contour.flatten().tolist()\n",
    "\n",
    "                        # Write to file\n",
    "                        line = f\"{class_id} \" + ' '.join(map(str, contour_list))\n",
    "                        f.write(line + '\\n')\n",
    "            else:\n",
    "                print(f\"No predicted masks for image {image_file}\")\n",
    "\n",
    "            # Process your own mask\n",
    "            # Threshold mask to binary\n",
    "            _, mask_bin = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(mask_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for contour in contours:\n",
    "                # Simplify contour\n",
    "                epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "                contour = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "                # Flatten contour array\n",
    "                contour = contour.squeeze()\n",
    "                if contour.ndim != 2:\n",
    "                    continue  # Skip if contour is not 2D\n",
    "\n",
    "                # Normalize coordinates\n",
    "                normalized_contour = contour.astype(np.float32)\n",
    "                normalized_contour[:, 0] /= original_width\n",
    "                normalized_contour[:, 1] /= original_height\n",
    "\n",
    "                # Flatten and convert to list\n",
    "                contour_list = normalized_contour.flatten().tolist()\n",
    "\n",
    "                # Write to file with mask_class_id\n",
    "                line = f\"{mask_class_id} \" + ' '.join(map(str, contour_list))\n",
    "                f.write(line + '\\n')\n",
    "\n",
    "        # Copy image to dataset folder\n",
    "        shutil.copy(image_path, os.path.join(dataset_root, 'images', phase, image_file))\n",
    "\n",
    "# Process train and val datasets\n",
    "process_dataset('train', train_files)\n",
    "process_dataset('val', val_files)\n",
    "\n",
    "# Generate dataset YAML file\n",
    "dataset_yaml = os.path.join(dataset_root, 'dataset.yaml')\n",
    "with open(dataset_yaml, 'w') as f:\n",
    "    f.write(f\"path: {dataset_root}\\n\")\n",
    "    f.write(\"train: images/train\\n\")\n",
    "    f.write(\"val: images/val\\n\")\n",
    "    f.write(\"test: \\n\\n\")\n",
    "    f.write(\"names:\\n\")\n",
    "    for class_id in sorted(class_names.keys()):\n",
    "        f.write(f\"  {class_id}: {class_names[class_id]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEO Dataset Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Data Process (for xyz rxyz is invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min x: -0.41059924008326715, Max x: 0.03631917139252827\n",
      "Min y: -0.7661798246708781, Max y: 0.29486756366552436\n",
      "Min z: 0.01451047114314541, Max z: 0.8342742760627375\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import pandas as pd\n",
    "data_path = '/home/capre/disk_4/yutao/data'\n",
    "\n",
    "def switch_xyzrxyz(rxyzxyz:list):\n",
    "    r_xyz, xyz = rxyzxyz[0:3], rxyzxyz[3:6]\n",
    "    xyzrxyz = np.hstack((xyz, r_xyz))\n",
    "    return xyzrxyz.tolist()\n",
    "\n",
    "# print(switch_xyzrxyz([1,2,3,4,5,6]))\n",
    "\n",
    "def transform_pose(pose: list, T_cam_to_base):\n",
    "    pose: np.ndarray = np.array(pose)\n",
    "    t_xyz = pose[0:3]\n",
    "    r_xyz = pose[3:6]\n",
    "    rotation_matrix = R.from_euler('xyz', r_xyz.reshape(1, 3), degrees=False).as_matrix().reshape(3, 3)\n",
    "    T_end_to_base = np.eye(4)\n",
    "    T_end_to_base[:3, :3] = rotation_matrix\n",
    "    T_end_to_base[:3, 3] = t_xyz.ravel()\n",
    "    T_base_to_cam = np.linalg.inv(T_cam_to_base)\n",
    "\n",
    "    T_cam_to_end = T_base_to_cam @ T_end_to_base\n",
    "    new_t = T_cam_to_end[:3, 3]\n",
    "    new_r = R.from_matrix(T_cam_to_end[:3, :3]).as_euler('xyz', degrees=False)\n",
    "    xyzrxrzry = np.hstack((new_r, new_t.reshape(-1)))\n",
    "    return xyzrxrzry.tolist()\n",
    "\n",
    "\n",
    "path = Path(data_path)\n",
    "resources_path: Path = path / 'resources'\n",
    "all_data = {}\n",
    "x_values, y_values, z_values = [], [], []\n",
    "\n",
    "for json_f in path.rglob(\"*saved_data.json\"):\n",
    "    related_calib_json = json_f.parent / 'Calibration_results' / 'calibration_results.json'\n",
    "    if related_calib_json.exists():\n",
    "        calib = json.load(open(related_calib_json))\n",
    "        saved_data = json.load(open(json_f))\n",
    "        save = True\n",
    "        for each_record in saved_data:\n",
    "            for each_image in saved_data[each_record]['color_files']:\n",
    "                if not resources_path.joinpath(each_image).exists():\n",
    "                    save = False\n",
    "                    break\n",
    "            if not save:\n",
    "                break\n",
    "            \n",
    "            for idx, pose in enumerate(saved_data[each_record]['poses']):\n",
    "                saved_data[each_record]['poses'][idx]['pose0'] = switch_xyzrxyz(saved_data[each_record]['poses'][idx]['pose0'])\n",
    "                if saved_data[each_record]['poses'][idx]['pose1'] is not None:\n",
    "                    saved_data[each_record]['poses'][idx]['pose1'] = switch_xyzrxyz(saved_data[each_record]['poses'][idx]['pose1'])\n",
    "\n",
    "\n",
    "            for idx, pose in enumerate(saved_data[each_record]['pose']):\n",
    "                saved_data[each_record]['pose'][idx] = switch_xyzrxyz(pose)\n",
    "                x_values.append(saved_data[each_record]['pose'][idx][0])\n",
    "                y_values.append(saved_data[each_record]['pose'][idx][1])\n",
    "                z_values.append(saved_data[each_record]['pose'][idx][2])\n",
    "            # print(saved_data[each_record])\n",
    "            all_data[each_record] = saved_data[each_record]\n",
    "            # break\n",
    "\n",
    "# Compute min and max for x, y, z\n",
    "min_x, max_x = min(x_values), max(x_values)\n",
    "min_y, max_y = min(y_values), max(y_values)\n",
    "min_z, max_z = min(z_values), max(z_values)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Min x: {min_x}, Max x: {max_x}\")\n",
    "print(f\"Min y: {min_y}, Max y: {max_y}\")\n",
    "print(f\"Min z: {min_z}, Max z: {max_z}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map id to real prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_map = pd.read_csv(path / 'task_list.csv')\n",
    "prompts_map['ID'] = prompts_map['ID'].astype(int).astype(str)\n",
    "\n",
    "for each_record in all_data:\n",
    "    all_data[each_record]['prompt'] = prompts_map[prompts_map['ID'] == all_data[each_record]['prompt']]['Prompts'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "half_data_len = len(all_data) // 2\n",
    "random_keys = random.sample(list(all_data.keys()), half_data_len)\n",
    "half_data = {key: all_data[key] for key in random_keys}\n",
    "print(len(half_data))\n",
    "json.dump(half_data, open(path / 'half_data.json', 'w'), indent=4)\n",
    "\n",
    "half_half_data_len = len(all_data) // 2 // 2\n",
    "random_keys = random.sample(list(all_data.keys()), half_half_data_len)\n",
    "half_half_data = {key: all_data[key] for key in random_keys}\n",
    "print(len(half_half_data))\n",
    "json.dump(half_half_data, open(path / 'half_half_data.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.goodFeaturesToTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plyfile\n",
    "data = plyfile.PlyData.read('/home/capre/disk_4/yutao/data/resources/0a7ee4d0cf344e15a81c68be0be1fb96_point_cloud_1.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PlyData((PlyElement('vertex', (PlyProperty('x', 'float'), PlyProperty('y', 'float'), PlyProperty('z', 'float'), PlyProperty('red', 'uchar'), PlyProperty('green', 'uchar'), PlyProperty('blue', 'uchar'), PlyProperty('segment_id', 'int')), count=208304, comments=[]),), text=True, byte_order='=', comments=[], obj_info=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! python launch.py task=tuning_vla note=tuning_vla pretrained_ckpt_path=/home/capre/disk_4/yutao/leo/ckpts clip_txt_guidance.flag=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recalculate the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from plyfile import PlyElement, PlyData\n",
    "import open3d as o3d\n",
    "import open3d.core as o3c\n",
    "# os.chdir(\"/home/capre/disk_4/yutao/ultralytics\")\n",
    "# Load a model\n",
    "model = YOLO(\"/home/capre/Point-Cloud-Stream/runs/segment/train6/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "o3d_device = o3d.core.Device(\"CUDA:0\")\n",
    "from utils.segmentation import segment_pcd_from_2d\n",
    "intrinsic = np.array([\n",
    "    [\n",
    "      610.5961520662408,\n",
    "      0.0,\n",
    "      639.8919938587554\n",
    "    ],\n",
    "    [\n",
    "      0.0,\n",
    "      617.4130735412369,\n",
    "      358.3889735843055\n",
    "    ],\n",
    "    [\n",
    "      0.0,\n",
    "      0.0,\n",
    "      1.0\n",
    "    ]\n",
    "  ]).T\n",
    "\n",
    "for idxx, each_record in enumerate(all_data):\n",
    "    print(f\"Processing {idxx}/{len(all_data)}: {each_record}\")\n",
    "    for idx, each_images in enumerate(all_data[each_record]['color_files']):\n",
    "        # print(each_image)\n",
    "        depth = resources_path / all_data[each_record]['depth_files'][idx]\n",
    "        color = resources_path / all_data[each_record]['color_files'][idx]\n",
    "        depth = np.load(str(depth))\n",
    "        depth = o3d.geometry.Image(depth)\n",
    "        color = o3d.io.read_image(str(color))\n",
    "        depth = o3d.t.geometry.Image.from_legacy(depth)\n",
    "        color = o3d.t.geometry.Image.from_legacy(color)\n",
    "        rgbd_image = o3d.t.geometry.RGBDImage(color, depth)\n",
    "        pcd_frame = o3d.t.geometry.PointCloud.create_from_rgbd_image(\n",
    "                    rgbd_image, \n",
    "                    o3c.Tensor(intrinsic, dtype=o3c.Dtype.Float32, device=o3d_device),\n",
    "                    o3c.Tensor(np.eye(4), dtype=o3c.Dtype.Float32, device=o3d_device),\n",
    "                    1000, 3,\n",
    "                    2, False)\n",
    "        xyz = np.asarray(pcd_frame.to_legacy().points)\n",
    "        rgb = np.asarray(pcd_frame.to_legacy().colors)\n",
    "        color_numpy = np.asarray(color.to_legacy())\n",
    "        print(color_numpy.shape)\n",
    "        # try:\n",
    "        label = segment_pcd_from_2d(model, pcd_frame, \n",
    "                                    resources_path / all_data[each_record]['color_files'][idx] \n",
    "                                    , intrinsic)\n",
    "        # except Exception as e:\n",
    "        #    print(resources_path / all_data[each_record]['color_files'][idx])\n",
    "        #    print(e)\n",
    "        pcd_with_labels = np.hstack((xyz, rgb, label.reshape(-1, 1)))\n",
    "        ply_name = resources_path / all_data[each_record]['point_cloud_files'][idx]\n",
    "        vertex = np.array(\n",
    "                    [(x, y, z, r, g, b, s) for x, y, z, r, g, b, s in pcd_with_labels],\n",
    "                    dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1'),\n",
    "                           ('segment_id', 'i4')])\n",
    "        ply = PlyData([PlyElement.describe(vertex, 'vertex')], text=True)\n",
    "        ply.write(str(ply_name))\n",
    "\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/home/capre/Point-Cloud-Stream/runs/segment/train6/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# results = model.train(data=\"Objects365.yaml\", epochs=100, imgsz=640)\n",
    "image_path =  '/home/capre/disk_4/yutao/data/resources/200a4ee908534e36a0aae0e39e2c8854_color_3.png'\n",
    "res= model.predict(source=image_path, save=False, verbose=False)\n",
    "res[0].show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "o3d311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
