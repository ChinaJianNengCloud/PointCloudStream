{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"./data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "file_contents = {}\n",
    "for json_f in path.rglob(\"sa*.json\"):\n",
    "    json_contents = json.loads(json_f.read_text())\n",
    "    print(len(json_contents))\n",
    "    file_contents.update(json_contents)\n",
    "    # break\n",
    "\n",
    "# Sort the file_contents by the 'prompt' field\n",
    "sorted_contents = OrderedDict(\n",
    "    sorted(file_contents.items(), key=lambda item: int(item[1]['prompt']))\n",
    ")\n",
    "\n",
    "output = Path(\"./data\") / \"lincheng\"\n",
    "output.mkdir(exist_ok=True)\n",
    "with open(output / \"saved_data.json\", \"w\") as f:\n",
    "    json.dump(sorted_contents, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolo finetun using different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics.utils.checks import check_requirements\n",
    "from ultralytics.utils.downloads import download\n",
    "from ultralytics.utils.ops import xyxy2xywhn\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "check_requirements(('pycocotools>=2.0',))\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Make Directories\n",
    "dir = Path('/home/capre/disk_4/yutao/ultralytics/datasets/Objects365')  # dataset root dir\n",
    "for p in 'images', 'labels':\n",
    "    (dir / p).mkdir(parents=True, exist_ok=True)\n",
    "    for q in 'train', 'val':\n",
    "        (dir / p / q).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Train, Val Splits\n",
    "for split, patches in [('train', 50 + 1), ('val', 43 + 1)]:\n",
    "    print(f\"Processing {split} in {patches} patches ...\")\n",
    "    images, labels = dir / 'images' / split, dir / 'labels' / split\n",
    "\n",
    "    # Download\n",
    "    url = f\"https://dorc.ks3-cn-beijing.ksyun.com/data-set/2020Objects365%E6%95%B0%E6%8D%AE%E9%9B%86/{split}/\"\n",
    "    if split == 'train':\n",
    "        download([f'{url}zhiyuan_objv2_{split}.tar.gz'], dir=dir)  # annotations json\n",
    "        download([f'{url}patch{i}.tar.gz' for i in range(patches)], dir=images, curl=True, threads=8)\n",
    "    elif split == 'val':\n",
    "        download([f'{url}zhiyuan_objv2_{split}.json'], dir=dir)  # annotations json\n",
    "        download([f'{url}images/v1/patch{i}.tar.gz' for i in range(15 + 1)], dir=images, curl=True, threads=8)\n",
    "        download([f'{url}images/v2/patch{i}.tar.gz' for i in range(16, patches)], dir=images, curl=True, threads=8)\n",
    "\n",
    "    # Move\n",
    "    for f in tqdm(images.rglob('*.jpg'), desc=f'Moving {split} images'):\n",
    "        f.rename(images / f.name)  # move to /images/{split}\n",
    "\n",
    "    # Labels\n",
    "    coco = COCO(dir / f'zhiyuan_objv2_{split}.json')\n",
    "    names = [x[\"name\"] for x in coco.loadCats(coco.getCatIds())]\n",
    "    for cid, cat in enumerate(names):\n",
    "        catIds = coco.getCatIds(catNms=[cat])\n",
    "        imgIds = coco.getImgIds(catIds=catIds)\n",
    "        for im in tqdm(coco.loadImgs(imgIds), desc=f'Class {cid + 1}/{len(names)} {cat}'):\n",
    "            width, height = im[\"width\"], im[\"height\"]\n",
    "            path = Path(im[\"file_name\"])  # image filename\n",
    "            try:\n",
    "                with open(labels / path.with_suffix('.txt').name, 'a') as file:\n",
    "                    annIds = coco.getAnnIds(imgIds=im[\"id\"], catIds=catIds, iscrowd=None)\n",
    "                    for a in coco.loadAnns(annIds):\n",
    "                        x, y, w, h = a['bbox']  # bounding box in xywh (xy top-left corner)\n",
    "                        xyxy = np.array([x, y, x + w, y + h])[None]  # pixels(1,4)\n",
    "                        x, y, w, h = xyxy2xywhn(xyxy, w=width, h=height, clip=True)[0]  # normalized and clipped\n",
    "                        file.write(f\"{cid} {x:.5f} {y:.5f} {w:.5f} {h:.5f}\\n\")\n",
    "            except Exception as e:\n",
    "                print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "# os.chdir(\"/home/capre/disk_4/yutao/ultralytics\")\n",
    "# Load a model\n",
    "model = YOLO(\"/home/capre/Point-Cloud-Stream/runs/segment/train6/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "# results = model.train(data=\"Objects365.yaml\", epochs=100, imgsz=640)\n",
    "image_path = '/home/capre/disk_4/yutao/data/resources/0a7ee4d0cf344e15a81c68be0be1fb96_color_2.png'\n",
    "res= model.predict(source=image_path, save=False, verbose=False)\n",
    "res[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolo finetune for breast seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11x-seg.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"/home/capre/disk_4/yutao/breast-seg/dataset3/dataset.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# masks filename align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def add_leading_zeros_to_masks(masks_dir, total_digits=4):\n",
    "    \"\"\"\n",
    "    将 masks_dir 中的文件名加上前导零，使其成为指定长度的数字字符串。\n",
    "\n",
    "    参数：\n",
    "    - masks_dir: 掩码文件夹的路径\n",
    "    - total_digits: 文件名应达到的总位数，默认为4\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(masks_dir):\n",
    "        # 分离文件名和扩展名\n",
    "        basename, extension = os.path.splitext(filename)\n",
    "        try:\n",
    "            # 将文件名转换为整数，以确保文件名是数字\n",
    "            number = int(basename)\n",
    "            # 格式化新的文件名，添加前导零\n",
    "            new_basename = f\"{number:0{total_digits}d}\"\n",
    "            new_filename = new_basename + extension\n",
    "            # 构建完整的源和目标路径\n",
    "            src = os.path.join(masks_dir, filename)\n",
    "            dst = os.path.join(masks_dir, new_filename)\n",
    "            # 重命名文件\n",
    "            os.rename(src, dst)\n",
    "            print(f\"重命名：{filename} -> {new_filename}\")\n",
    "        except ValueError:\n",
    "            print(f\"跳过非数字文件名：{filename}\")\n",
    "\n",
    "# 使用示例：\n",
    "masks_dir = '/home/capre/disk_4/yutao/breast-seg/masks'  # 替换为您的 masks 文件夹路径\n",
    "add_leading_zeros_to_masks(masks_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolo dataset make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "images_dir = '/home/capre/disk_4/yutao/breast-seg/images'  # Replace with your images directory\n",
    "masks_dir = '/home/capre/disk_4/yutao/breast-seg/masks'      # Replace with your masks directory\n",
    "dataset_root = '/home/capre/disk_4/yutao/breast-seg/dataset2'  # Replace with your dataset root directory\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(os.path.join(dataset_root, 'images', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'images', 'val'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'labels', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'labels', 'val'), exist_ok=True)\n",
    "\n",
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Shuffle and split into train and val\n",
    "random.shuffle(image_files)\n",
    "split_index = int(len(image_files) * 0.8)\n",
    "train_files = image_files[:split_index]\n",
    "val_files = image_files[split_index:]\n",
    "\n",
    "def process_dataset(phase, files):\n",
    "    for image_file in files:\n",
    "        # Read image and mask\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        mask_path = os.path.join(masks_dir, image_file)  # Assuming mask has the same name\n",
    "        image = cv2.imread(image_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Check if mask exists\n",
    "        if mask is None:\n",
    "            print(f\"Mask not found for image {image_file}\")\n",
    "            continue\n",
    "\n",
    "        height, width = mask.shape\n",
    "        # Threshold mask to binary\n",
    "        _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create label file\n",
    "        label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "        label_path = os.path.join(dataset_root, 'labels', phase, label_file)\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            for contour in contours:\n",
    "                # Simplify contour\n",
    "                epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "                contour = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "                # Flatten contour array\n",
    "                contour = contour.squeeze()\n",
    "                if contour.ndim != 2:\n",
    "                    continue  # Skip if contour is not 2D\n",
    "\n",
    "                # Normalize coordinates\n",
    "                normalized_contour = contour.astype(np.float32)\n",
    "                normalized_contour[:, 0] /= width\n",
    "                normalized_contour[:, 1] /= height\n",
    "\n",
    "                # Flatten and convert to list\n",
    "                contour_list = normalized_contour.flatten().tolist()\n",
    "\n",
    "                # Write to file (class index is 0)\n",
    "                line = '0 ' + ' '.join(map(str, contour_list))\n",
    "                f.write(line + '\\n')\n",
    "\n",
    "        # Copy image to dataset folder\n",
    "        shutil.copy(image_path, os.path.join(dataset_root, 'images', phase, image_file))\n",
    "\n",
    "        # Visualization (optional)\n",
    "        # if random.random() < 0.05:  # Adjust the probability as needed\n",
    "        #     # Plot image and contours\n",
    "        #     plt.figure(figsize=(10, 10))\n",
    "        #     plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        #     for contour in contours:\n",
    "        #         contour = contour.squeeze()\n",
    "        #         plt.plot(contour[:, 0], contour[:, 1], linewidth=2)\n",
    "        #     plt.title(f\"{phase} - {image_file}\")\n",
    "        #     plt.axis('off')\n",
    "        #     plt.show()\n",
    "\n",
    "# Process train and val datasets\n",
    "process_dataset('train', train_files)\n",
    "process_dataset('val', val_files)\n",
    "\n",
    "# Generate dataset YAML file\n",
    "dataset_yaml = os.path.join(dataset_root, 'dataset.yaml')\n",
    "with open(dataset_yaml, 'w') as f:\n",
    "    f.write(f\"path: {dataset_root}\\n\")\n",
    "    f.write(\"train: images/train\\n\")\n",
    "    f.write(\"val: images/val\\n\")\n",
    "    f.write(\"test: \\n\\n\")\n",
    "    f.write(\"names:\\n\")\n",
    "    f.write(\"  0: object\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add label from predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define paths\n",
    "images_dir = '/home/capre/disk_4/yutao/breast-seg/images'  # Replace with your images directory\n",
    "masks_dir = '/home/capre/disk_4/yutao/breast-seg/masks'      # Replace with your masks directory\n",
    "dataset_root = '/home/capre/disk_4/yutao/breast-seg/dataset3'  # Replace with your dataset root directory\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(os.path.join(dataset_root, 'images', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'images', 'val'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'labels', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_root, 'labels', 'val'), exist_ok=True)\n",
    "\n",
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Shuffle and split into train and val\n",
    "random.shuffle(image_files)\n",
    "split_index = int(len(image_files) * 0.8)\n",
    "train_files = image_files[:split_index]\n",
    "val_files = image_files[split_index:]\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolo11x-seg.pt')  # Replace with the correct path to your model\n",
    "\n",
    "# Get class names and assign a new class ID for your mask label\n",
    "class_names = model.names  # A dictionary {class_id: class_name}\n",
    "max_class_id = max(class_names.keys())\n",
    "mask_class_id = max_class_id + 1\n",
    "class_names[mask_class_id] = 'breast'  # Replace 'breast' with your class name\n",
    "\n",
    "def process_dataset(phase, files):\n",
    "    for image_file in files:\n",
    "        # Read image and mask\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "        mask_path = os.path.join(masks_dir, image_file)  # Assuming mask has the same name\n",
    "        image = cv2.imread(image_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Check if mask exists\n",
    "        if mask is None:\n",
    "            print(f\"Mask not found for image {image_file}\")\n",
    "            continue\n",
    "\n",
    "        original_height, original_width = image.shape[:2]\n",
    "\n",
    "        # Run the model to get predictions\n",
    "        results = model.predict(source=image, save=False, verbose=False)\n",
    "        result = results[0]\n",
    "\n",
    "        # Create label file\n",
    "        label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "        label_path = os.path.join(dataset_root, 'labels', phase, label_file)\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            # Process predicted masks\n",
    "            if hasattr(result, 'masks') and result.masks is not None:\n",
    "                pred_masks = result.masks.data.cpu().numpy()\n",
    "                pred_classes = result.boxes.cls.cpu().numpy().astype(int)\n",
    "                for mask_pred, class_id in zip(pred_masks, pred_classes):\n",
    "                    # Convert mask to binary image\n",
    "                    mask_pred = (mask_pred > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "                    # Resize mask back to original image size\n",
    "                    mask_pred_resized = cv2.resize(mask_pred, (original_width, original_height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "                    # Find contours\n",
    "                    contours, _ = cv2.findContours(mask_pred_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                    for contour in contours:\n",
    "                        # Simplify contour\n",
    "                        epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "                        contour = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "                        # Flatten contour array\n",
    "                        contour = contour.squeeze()\n",
    "                        if contour.ndim != 2:\n",
    "                            continue  # Skip if contour is not 2D\n",
    "\n",
    "                        # Normalize coordinates\n",
    "                        normalized_contour = contour.astype(np.float32)\n",
    "                        normalized_contour[:, 0] /= original_width\n",
    "                        normalized_contour[:, 1] /= original_height\n",
    "\n",
    "                        # Flatten and convert to list\n",
    "                        contour_list = normalized_contour.flatten().tolist()\n",
    "\n",
    "                        # Write to file\n",
    "                        line = f\"{class_id} \" + ' '.join(map(str, contour_list))\n",
    "                        f.write(line + '\\n')\n",
    "            else:\n",
    "                print(f\"No predicted masks for image {image_file}\")\n",
    "\n",
    "            # Process your own mask\n",
    "            # Threshold mask to binary\n",
    "            _, mask_bin = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(mask_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for contour in contours:\n",
    "                # Simplify contour\n",
    "                epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "                contour = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "                # Flatten contour array\n",
    "                contour = contour.squeeze()\n",
    "                if contour.ndim != 2:\n",
    "                    continue  # Skip if contour is not 2D\n",
    "\n",
    "                # Normalize coordinates\n",
    "                normalized_contour = contour.astype(np.float32)\n",
    "                normalized_contour[:, 0] /= original_width\n",
    "                normalized_contour[:, 1] /= original_height\n",
    "\n",
    "                # Flatten and convert to list\n",
    "                contour_list = normalized_contour.flatten().tolist()\n",
    "\n",
    "                # Write to file with mask_class_id\n",
    "                line = f\"{mask_class_id} \" + ' '.join(map(str, contour_list))\n",
    "                f.write(line + '\\n')\n",
    "\n",
    "        # Copy image to dataset folder\n",
    "        shutil.copy(image_path, os.path.join(dataset_root, 'images', phase, image_file))\n",
    "\n",
    "# Process train and val datasets\n",
    "process_dataset('train', train_files)\n",
    "process_dataset('val', val_files)\n",
    "\n",
    "# Generate dataset YAML file\n",
    "dataset_yaml = os.path.join(dataset_root, 'dataset.yaml')\n",
    "with open(dataset_yaml, 'w') as f:\n",
    "    f.write(f\"path: {dataset_root}\\n\")\n",
    "    f.write(\"train: images/train\\n\")\n",
    "    f.write(\"val: images/val\\n\")\n",
    "    f.write(\"test: \\n\\n\")\n",
    "    f.write(\"names:\\n\")\n",
    "    for class_id in sorted(class_names.keys()):\n",
    "        f.write(f\"  {class_id}: {class_names[class_id]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEO Dataset Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Data Process (for xyz rxyz is invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import pandas as pd\n",
    "data_path = '/home/capre/disk_4/yutao/leo_data/data_2nd'\n",
    "\n",
    "\n",
    "# def switch_xyzrxyz(rxyzxyz:list):\n",
    "#     r_xyz, xyz = rxyzxyz[0:3], rxyzxyz[3:6]\n",
    "#     xyzrxyz = np.hstack((xyz, r_xyz))\n",
    "#     return xyzrxyz.tolist()\n",
    "\n",
    "# print(switch_xyzrxyz([1,2,3,4,5,6]))\n",
    "\n",
    "# def transform_pose(pose: list, T_cam_to_base):\n",
    "#     pose: np.ndarray = np.array(pose)\n",
    "#     t_xyz = pose[0:3]\n",
    "#     r_xyz = pose[3:6]\n",
    "#     rotation_matrix = R.from_euler('xyz', r_xyz.reshape(1, 3), degrees=False).as_matrix().reshape(3, 3)\n",
    "#     T_end_to_base = np.eye(4)\n",
    "#     T_end_to_base[:3, :3] = rotation_matrix\n",
    "#     T_end_to_base[:3, 3] = t_xyz.ravel()\n",
    "#     T_base_to_cam = np.linalg.inv(T_cam_to_base)\n",
    "\n",
    "#     T_cam_to_end = T_base_to_cam @ T_end_to_base\n",
    "#     new_t = T_cam_to_end[:3, 3]\n",
    "#     new_r = R.from_matrix(T_cam_to_end[:3, :3]).as_euler('xyz', degrees=False)\n",
    "#     xyzrxrzry = np.hstack((new_r, new_t.reshape(-1)))\n",
    "#     return xyzrxrzry.tolist()\n",
    "\n",
    "\n",
    "path = Path(data_path)\n",
    "resources_path: Path = path / 'resources'\n",
    "all_data = {}\n",
    "x_values, y_values, z_values = [], [], []\n",
    "\n",
    "\n",
    "import re\n",
    "pattern = re.compile(r'(\\d+$)')\n",
    "\n",
    "\n",
    "for json_f in path.rglob(\"*saved_data.json\"):\n",
    "    # related_calib_json = json_f.parent / 'Calibration_results' / 'calibration_results.json'\n",
    "    # if related_calib_json.exists():\n",
    "        # calib = json.load(open(related_calib_json))\n",
    "    saved_data = json.load(open(json_f))\n",
    "    save = True\n",
    "    for each_record in saved_data:\n",
    "        prompt = saved_data[each_record]['prompt']\n",
    "        if pattern.search(prompt):\n",
    "            print(pattern.sub(\"\", prompt))\n",
    "            saved_data[each_record]['prompt'] = pattern.sub(\"\", prompt)\n",
    "            \n",
    "        for each_image in saved_data[each_record]['color_files']:\n",
    "            if not resources_path.joinpath(each_image).exists():\n",
    "                save = False\n",
    "                break\n",
    "        if not save:\n",
    "            break\n",
    "        \n",
    "        # for idx, pose in enumerate(saved_data[each_record]['poses']):\n",
    "        #     saved_data[each_record]['poses'][idx]['pose0'] = switch_xyzrxyz(saved_data[each_record]['poses'][idx]['pose0'])\n",
    "        #     if saved_data[each_record]['poses'][idx]['pose1'] is not None:\n",
    "        #         saved_data[each_record]['poses'][idx]['pose1'] = switch_xyzrxyz(saved_data[each_record]['poses'][idx]['pose1'])\n",
    "\n",
    "\n",
    "        for idx, pose in enumerate(saved_data[each_record]['pose']):\n",
    "            # saved_data[each_record]['pose'][idx] = switch_xyzrxyz(pose)\n",
    "            x_values.append(saved_data[each_record]['pose'][idx][0])\n",
    "            y_values.append(saved_data[each_record]['pose'][idx][1])\n",
    "            z_values.append(saved_data[each_record]['pose'][idx][2])\n",
    "        # print(saved_data[each_record])\n",
    "        all_data[each_record] = saved_data[each_record]\n",
    "        # break\n",
    "\n",
    "# Compute min and max for x, y, z\n",
    "min_x, max_x = min(x_values), max(x_values)\n",
    "min_y, max_y = min(y_values), max(y_values)\n",
    "min_z, max_z = min(z_values), max(z_values)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Min x: {min_x}, Max x: {max_x}\")\n",
    "print(f\"Min y: {min_y}, Max y: {max_y}\")\n",
    "print(f\"Min z: {min_z}, Max z: {max_z}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map id to real prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_map = pd.read_csv(path / 'task_list.csv')\n",
    "prompts_map['ID'] = prompts_map['ID'].astype(int).astype(str)\n",
    "\n",
    "for each_record in all_data:\n",
    "    all_data[each_record]['prompt'] = prompts_map[prompts_map['ID'] == all_data[each_record]['prompt']]['Prompts'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "all_data_len = len(all_data)\n",
    "random_keys = random.sample(list(all_data.keys()), all_data_len)\n",
    "all_data = {key: all_data[key] for key in random_keys}\n",
    "print(len(all_data))\n",
    "json.dump(all_data, open(path / 'all_data.json', 'w'), indent=4)\n",
    "\n",
    "half_data_len = len(all_data) // 2\n",
    "random_keys = random.sample(list(all_data.keys()), half_data_len)\n",
    "half_data = {key: all_data[key] for key in random_keys}\n",
    "print(len(half_data))\n",
    "json.dump(half_data, open(path / 'half_data.json', 'w'), indent=4)\n",
    "\n",
    "half_half_data_len = len(all_data) // 2 // 2\n",
    "random_keys = random.sample(list(all_data.keys()), half_half_data_len)\n",
    "half_half_data = {key: all_data[key] for key in random_keys}\n",
    "print(len(half_half_data))\n",
    "json.dump(half_half_data, open(path / 'half_half_data.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch process seg pcd from yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from plyfile import PlyElement, PlyData\n",
    "import open3d as o3d\n",
    "import open3d.core as o3c\n",
    "import json\n",
    "import torch\n",
    "import cv2\n",
    "import torch.utils.dlpack\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from app.utils.camera.segmentation_utils import read_ply_to_numpy, batch_segment_and_label\n",
    "# Initialize YOLO model\n",
    "model = YOLO(\"/home/capre/Point-Cloud-Stream/runs/segment/train6/weights/best.pt\")\n",
    "\n",
    "o3d_device = o3d.core.Device(\"CUDA:0\")\n",
    "path = Path(\"/home/capre/disk_4/yutao/leo_data/data_2nd\")\n",
    "resources_path = path / 'resources'\n",
    "all_data = json.load(open(path / 'all_data.json'))\n",
    "# Intrinsic matrix\n",
    "intrinsic = np.array([\n",
    "    [610.5961520662408, 0.0,               639.8919938587554],\n",
    "    [0.0,               617.4130735412369, 358.3889735843055],\n",
    "    [0.0,               0.0,               1.0]\n",
    "], dtype=np.float32).T\n",
    "\n",
    "\n",
    "def o3d_t_to_torch(o3d_t):\n",
    "    return torch.utils.dlpack.from_dlpack(o3d_t.to_dlpack())\n",
    "\n",
    "\n",
    "batch_pcds = []\n",
    "batch_rgbs = []\n",
    "\n",
    "batch_intrinsics = []\n",
    "batch_extrinsics = []\n",
    "batch_info = []  # (each_record, idx)\n",
    "res_data = {}\n",
    "\n",
    "record_keys = list(all_data.keys())\n",
    "for each_record in tqdm(record_keys, desc='Calculate Seg Label'):\n",
    "    current_pcds = []\n",
    "    current_imgs = []\n",
    "    current_intrs = []\n",
    "    current_extrs = []\n",
    "    current_info = []\n",
    "    saved = True\n",
    "    \n",
    "    for idx, each_image in enumerate(all_data[each_record]['color_files']):\n",
    "        try:\n",
    "            color_path = resources_path / each_image\n",
    "            point_cloud = read_ply_to_numpy(resources_path / all_data[each_record]['point_cloud_files'][idx])\n",
    "            full_color = cv2.imread(color_path)\n",
    "            current_pcds.append(point_cloud)\n",
    "            current_imgs.append(full_color)\n",
    "            current_extrs.append(np.eye(4))\n",
    "            current_intrs.append(intrinsic)\n",
    "            current_info.append([each_record, idx])\n",
    "        except Exception as e:\n",
    "            print(f\"{each_image}\", e)\n",
    "            saved = False\n",
    "            break\n",
    "    if saved:\n",
    "        batch_pcds.extend(current_pcds)\n",
    "        batch_rgbs.extend(current_imgs)\n",
    "        batch_extrinsics.extend(current_extrs)\n",
    "        batch_intrinsics.extend(current_intrs)\n",
    "        batch_info.extend(current_info)\n",
    "        res_data[each_record] = all_data[each_record]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.camera.segmentation_utils import segment_image_with_yolo, label_point_cloud_from_segmentation\n",
    "\n",
    "def batch_segment_and_label(model, point_clouds, color_images, intrinsics, extrinsics):\n",
    "    \"\"\"\n",
    "    Batch process point clouds and color images for segmentation and labeling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : YOLO\n",
    "        Segmentation model.\n",
    "    point_clouds : list\n",
    "        List of point clouds.\n",
    "    color_images : list\n",
    "        List of color images.\n",
    "    intrinsics : list\n",
    "        List of intrinsic matrices.\n",
    "    extrinsics : list\n",
    "        List of extrinsic matrices.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : list\n",
    "        List of labeled point clouds.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for pcd, color, intrinsic, extrinsic in zip(point_clouds, color_images, intrinsics, extrinsics):\n",
    "        res, H, W = segment_image_with_yolo(model, color)\n",
    "        try:\n",
    "            labels = label_point_cloud_from_segmentation(res, pcd, intrinsic, extrinsic, H, W)\n",
    "        except:\n",
    "            labels = np.zeros(pcd.shape[0], dtype=np.int64)\n",
    "        results.append(labels)\n",
    "        # print(np.count_nonzero(labels==80))\n",
    "    return results\n",
    "\n",
    "\n",
    "batch_pcds_pos = [pcd[:, 0:3] for pcd in batch_pcds]\n",
    "labels_list = batch_segment_and_label(model, batch_pcds_pos, \n",
    "                                      batch_rgbs, batch_intrinsics, batch_extrinsics)\n",
    "\n",
    "for i, labels in tqdm(enumerate(labels_list), desc='Saving ply', total=len(labels_list)):\n",
    "    print(np.count_nonzero(labels==80))\n",
    "    record, idx = batch_info[i]\n",
    "    pcd = batch_pcds[i]\n",
    "    ply_name = resources_path / all_data[record]['point_cloud_files'][idx]\n",
    "    # pcd = read_ply_to_numpy(ply_name)\n",
    "    pcd[:, 6] = labels\n",
    "    vertex = np.array(\n",
    "        [(x_p, y_p, z_p, r_p, g_p, b_p, s_p) for x_p, y_p, z_p, r_p, g_p, b_p, s_p in pcd],\n",
    "        dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "               ('red', 'f4'), ('green', 'f4'), ('blue', 'f4'), ('segment_id', 'i4')]\n",
    "    )\n",
    "    ply = PlyData([PlyElement.describe(vertex, 'vertex')], text=True)\n",
    "    ply.write(str(ply_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "model = YOLO(\"/home/capre/Point-Cloud-Stream/runs/segment/train6/weights/best.pt\")\n",
    "intrinsic = np.array([[624.8504238317045,   0.0,                657.0969388474656],\n",
    "                        [0.0,               627.2424412728651,  346.1339921256911],\n",
    "                        [0.0,               0.0,                1.0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.utils.camera.segmentation_utils import segment_pcd_from_2d, read_ply_to_numpy\n",
    "from plyfile import PlyData, PlyElement\n",
    "import cv2\n",
    "\n",
    "pcd = read_ply_to_numpy('/home/capre/disk_4/yutao/leo_data/data_2nd/resources/0acd5ab6fd3341ca8a26b6508f311a85_point_cloud_0.ply')\n",
    "# image = cv2.imread('/home/capre/disk_4/yutao/leo_data/data_1st/resources/0a7ee4d0cf344e15a81c68be0be1fb96_color_3.png')\n",
    "# labels = segment_pcd_from_2d(model, pcd, image, intrinsic)\n",
    "np.max(pcd[:,3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "o3d311vtk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
